---
layout: post
title: Crawling d·ªØ li·ªáu t·ª´ website
subtitle: Web scraping in 2023
author: "Deepak Bhardwaj"
tags:
- Web Scraping
- Web Data Scraping
- Data Scraping
- Crawl Data
- Data Mining
- Data Extraction
- Technology
---

D·ªØ li·ªáu ƒë√£ v√† ƒëang tr·ªü th√†nh m·ªôt ph·∫ßn ch√≠nh trong chi·∫øn l∆∞·ª£c tƒÉng tr∆∞·ªüng c·ªßa m·ªçi c√¥ng ty. C√°c d·ªØ li·ªáu n√†y bao g·ªìm:
- D·ªØ li·ªáu c√¥ng khai.
- D·ªØ li·ªáu th√¥ng tin ng∆∞·ªùi d√πng.
- D·ªØ li·ªáu c·ªßa ƒë·ªëi th·ªß c·∫°nh tranh.
- D·ªØ li·ªáu th·ªã tr∆∞·ªùng ch·ª©ng kho√°n.
- D·ªØ li·ªáu s·∫£n ph·∫©m.
- D·ªØ li·ªáu c√¥ng vi·ªác.
- D·ªØ li·ªáu d·ª± b√°o th·ªùi ti·∫øt v...v...

![Web Scraping](https://boxxv.github.io/img/2023/9LFFMbOMFJ3P7xs2yGHrDQukzea6scjQ8E20oyx2.jpeg "Web Scraping")

## Crawl l√† g√¨? Web Crawler l√† g√¨?

`Crawl` l√† c√†o d·ªØ li·ªáu (`Crawl Data`)

T·ª´ **crawl** (thu th·∫≠p th√¥ng tin) trong c·ª•m Tr√¨nh thu th·∫≠p th√¥ng tin web (`Web crawlers`) l√† thu·∫≠t ng·ªØ k·ªπ thu·∫≠t d√πng ƒë·ªÉ ch·ªâ qu√° tr√¨nh t·ª± ƒë·ªông truy c·∫≠p website v√† l·∫•y d·ªØ li·ªáu th√¥ng qua m·ªôt ch∆∞∆°ng tr√¨nh ph·∫ßn m·ªÅm.

Internet kh√¥ng ng·ª´ng thay ƒë·ªïi v√† m·ªü r·ªông. V√¨ kh√¥ng th·ªÉ bi·∫øt t·ªïng s·ªë website c√≥ tr√™n Internet, web crawlers b·∫Øt ƒë·∫ßu t·ª´ m·ªôt danh s√°ch c√°c URL ƒë√£ bi·∫øt. Tr∆∞·ªõc ti√™n, ch√∫ng thu th·∫≠p d·ªØ li·ªáu webpage t·∫°i c√°c URL ƒë√≥. T·ª´ c√°c page n√†y, ch√∫ng s·∫Ω t√¨m th·∫•y c√°c si√™u li√™n k·∫øt ƒë·∫øn nhi·ªÅu URL kh√°c v√† th√™m c√°c li√™n k·∫øt m·ªõi t√¨m ƒë∆∞·ª£c v√†o danh s√°ch c√°c trang c·∫ßn thu th·∫≠p th√¥ng tin ti·∫øp theo.


#### T·∫°i sao Web Crawlers ƒë∆∞·ª£c g·ªçi l√† ‚Äòspiders‚Äô?

Internet, ho·∫∑c √≠t nh·∫•t l√† ph·∫ßn m√† h·∫ßu h·∫øt ng∆∞·ªùi d√πng truy c·∫≠p, c√≤n ƒë∆∞·ª£c g·ªçi l√† World Wide Web ‚Äì tr√™n th·ª±c t·∫ø, ƒë√≥ l√† n∆°i xu·∫•t ph√°t ph·∫ßn ‚Äúwww‚Äù c·ªßa h·∫ßu h·∫øt c√°c URL trang web. 

Vi·ªác g·ªçi c√°c bot c·ªßa c√¥ng c·ª• t√¨m ki·∫øm l√† ‚Äúspiders‚Äù l√† ƒëi·ªÅu ho√†n to√†n t·ª± nhi√™n, b·ªüi v√¨ ch√∫ng thu th·∫≠p d·ªØ li·ªáu tr√™n kh·∫Øp c√°c trang Web, gi·ªëng nh∆∞ nh·ªØng con nh·ªán b√≤ tr√™n m·∫°ng nh·ªán.


![Web Scraping](https://boxxv.github.io/img/2023/what-is-web-sraping-parsehub.jpeg "Web Scraping")

## Scraping data l√† g√¨?

Scraping d·ªØ li·ªáu kh√¥ng nh·∫•t thi·∫øt ph·∫£i li√™n quan ƒë·∫øn web. Scraping c√≥ th·ªÉ ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác tr√≠ch xu·∫•t th√¥ng tin t·ª´ m·ªôt h·ªá th·ªëng c·ª•c b·ªô, c∆° s·ªü d·ªØ li·ªáu chung ho·∫∑c th·∫≠m ch√≠ t·ª´ internet. Web Scaping c≈©ng th·ª±c hi·ªán vi·ªác t√¨m ki·∫øm v√† thu th·∫≠p th√¥ng tin nh∆∞ng kh√°c v·ªõi Web Crawling, Web Scraping kh√¥ng thu th·∫≠p to√†n b·ªô th√¥ng tin c·ªßa m·ªôt trang web m√† ch·ªâ thu th·∫≠p nh·ªØng th√¥ng tin c·∫ßn thi·∫øt, ph√π h·ª£p v·ªõi m·ª•c ƒë√≠ch c·ªßa ng∆∞·ªùi d√πng. Trong WebScraping ch√∫ng ta c≈©ng ph·∫ßn n√†o s·ª≠ d·ª•ng WebCrawler ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu, k·∫øt h·ª£p v·ªõi Data Extraction (tr√≠ch xu·∫•t d·ªØ li·ªáu) ƒë·ªÉ t·∫≠p trung v√†o c√°c n·ªôi dung c·∫ßn thi·∫øt.

V√≠ d·ª• nh∆∞ ƒë·ªëi v·ªõi trang amazon.com, Web Crawling s·∫Ω thu th·∫≠p to√†n b·ªô n·ªôi dung c·ªßa trang web n√†y (t√™n c√°c s·∫£n ph·∫©m, th√¥ng tin chi ti·∫øt, b·∫£ng gi√°, h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng, c√°c reviews v√† comments v·ªÅ s·∫£n ph·∫©m,‚Ä¶). Tuy nhi√™n Web Scaping c√≥ th·ªÉ ch·ªâ thu th·∫≠p th√¥ng tin v·ªÅ gi√° c·ªßa c√°c s·∫£n ph·∫©m ƒë·ªÉ ti·∫øn h√†nh so s√°nh gi√° n√†y v·ªõi c√°c trang b√°n h√†ng online kh√°c.

### S·ª± kh√°c bi·ªát gi·ªØa Web Crawling v√† Web Scraping

`Data scraping`, `web scraping` ho·∫∑c `content scraping` l√† h√†nh ƒë·ªông m·ªôt bot t·∫£i xu·ªëng n·ªôi dung tr√™n m·ªôt trang web m√† kh√¥ng ƒë∆∞·ª£c cho ph√©p b·ªüi ch·ªß website, th∆∞·ªùng v·ªõi m·ª•c ƒë√≠ch s·ª≠ d·ª•ng n·ªôi dung ƒë√≥ cho m·ª•c ƒë√≠ch x·∫•u.

Web scraping th∆∞·ªùng ƒë∆∞·ª£c target nhi·ªÅu h∆°n web crawling. Web scrapers c√≥ th·ªÉ ch·ªâ theo d√µi m·ªôt s·ªë trang websites c·ª• th·ªÉ, trong khi web crawlers s·∫Ω ti·∫øp t·ª•c theo d√µi c√°c li√™n k·∫øt v√† thu th·∫≠p th√¥ng tin c√°c trang li√™n t·ª•c.

B√™n c·∫°nh ƒë√≥, web scraper bots c√≥ th·ªÉ qua m·∫∑t m√°y ch·ªß d·ªÖ d√†ng, trong khi web crawlers, ƒë·∫∑c bi·ªát l√† t·ª´ c√°c c√¥ng c·ª• t√¨m ki·∫øm l·ªõn, s·∫Ω tu√¢n theo t·ªáp robots.txt v√† gia h·∫°n c√°c y√™u c·∫ßu c·ªßa ch√∫ng ƒë·ªÉ kh√¥ng ƒë√°nh l·ª´a m√°y ch·ªß web.

### Anti-bot detection

Khi c√†o d·ªØ li·ªáu th√¨ b·∫°n c√≥ th·ªÉ g·∫∑p nh·ªØng websites s·ª≠ d·ª•ng c√°c c∆° ch·∫ø ch·∫∑n bot (dƒ© nhi√™n h·ªç s·∫Ω ko ch·∫∑n c√°c Search engine n·ªïi ti·∫øng nh∆∞ Google, Bing,... r·ªìi). H·ªç c√≥ th·ªÉ s·∫Ω s·ª≠ d·ª•ng c√°c c∆° ch·∫ø:

- Ph√°t hi·ªán user-agents truy c·∫≠p nhi·ªÅu ‚Äî> Gi·∫£i ph√°p: d√πng user-agent kh√°c nhau ho·∫∑c d√πng SE agents n·ªïi ti·∫øng cho m·ªói l·∫ßn request. Danh s√°ch 450 User-Agents download t·∫°i: [Chia s·∫ª danh s√°ch User Agent th√¥ng d·ª•ng nh·∫•t](http://cafemmo.club/threads/chia-se-danh-sach-user-agent-thong-dung-nhat.1818/)
- Ph√°t hi·ªán IPs truy c·∫≠p nhi·ªÅu, gi·∫£ s·ª≠ 5 requests/s --> Gi·∫£i ph√°p: d√πng c√°c d·ªãch v·ª• IP rotator cho m·ªói l·∫ßn request. M√¨nh d√πng stormproxies.com.
- Ph√°t hi·ªán ng∆∞·ªùi d√πng th·∫≠t qua Javascript, ƒëa s·ªë bot ko h·ªó tr·ª£ JS m√† --> Gi·∫£i ph√°p: d√πng headless browser nh∆∞ Splash, Selenium, PhantomJS, Puppeter,... C√≥ kh√° nhi·ªÅu sites m√¨nh g·∫∑p d√πng JS ƒë·ªÉ detect robot nh∆∞ similarweb.com,...
- S·ª≠ d·ª•ng honeypot traps: v√≠ d·ª• nh∆∞ c√°c links b·∫©y ƒë√≠nh k√®m display:none, visibility: hidden,... --> c√†i ƒë·∫∑t c∆° ch·∫ø ph√°t hi·ªán c√°c traps th√¥i ^^
- S·ª≠ d·ª•ng cookie, captcha ƒë·ªÉ ch·∫∑n, ƒëa s·ªë sites d√πng Cloudflare ƒë·ªÉ ch·∫∑n bot --> c√≥ v√†i script bypass Cloudflare r·ªìi, s·ª≠ d·ª•ng nh∆∞ https://github.com/Anorov/cloudflare-scrape (script n√†y bypass cookie c·ªßa Cloudflare nh∆∞ng ch∆∞a c√≥ c∆° ch·∫ø bypass captcha c·ªßa Cloudflare nh√©).

### Ghi k·∫øt qu·∫£ d·ªØ li·ªáu (scraped data) qu√° nhi·ªÅu

Khi b·∫°n c√†o d·ªØ li·ªáu v·ªõi nhi·ªÅu spiders, v√≠ d·ª• 1 spider c√†o ƒë∆∞·ª£c 1 record/2s, v√† b·∫°n c√≥ 20 spiders th√¨ b·∫°n c√≥ 10 records/s, l√∫c n√†y vi·ªác ghi d·ªØ li·ªáu qu√° nhi·ªÅu v√† li√™n t·ª•c v√†o DB s·∫Ω l√†m cho DB c·ªßa b·∫°n qu√° t·∫£i v√† gi·∫£m hi·ªáu nƒÉng, c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu nƒÉng ho·∫°t ƒë·ªông. Khi ƒë√≥, b·∫°n n√™n c√¢n nh·∫Øc d√πng:

- Bulk insert query: t·ª©c spider ch·ªâ c·∫ßn th·ª±c hi·ªán 1 query ƒë·ªÉ insert nhi·ªÅu records
- Bulk import file: t·ª©c l√† spider ghi d·ªØ li·ªáu v√†o 1 file v·ªõi 1000 d·ªØ li·ªáu ch·∫≥ng h·∫°n, sau ƒë√≥ b·∫°n s·ª≠ d·ª•ng l·ªánh import file ƒë√≥ v√†o DB. V√≠ d·ª•: MySQL (LOAD DATA LOCAL INFILE), MongoDB (mongoimport) C√°c DB engines n√†o c≈©ng h·ªó tr·ª£ 2 d·∫°ng tr√™n, v√≠ d·ª• nh∆∞ MySQL, MongoDB,...

### C·∫•u tr√∫c site thay ƒë·ªïi

V√≠ d·ª• nh∆∞ site thay ƒë·ªïi layout, t·ª©c HTML tags thay ƒë·ªïi, l√∫c n√†y b·∫°n ph·∫£i thay ƒë·ªïi c√°c selectors ƒë·ªÉ l·∫•y ƒë√∫ng d·ªØ li·ªáu b·∫°n c·∫ßn. Trong t√¨nh hu·ªëng n√†y, spider c·∫ßn c√≥ c∆° ch·∫ø ph√°t hi·ªán s·ª± thay ƒë·ªïi c·∫•u tr√∫c site ƒë·ªÉ th√¥ng b√°o cho ch√∫ng ta v√† d·ª´ng extract data c·ªßa site ƒë√≥. Khi ƒë√≥, m·ªói site ta c·∫ßn h·ªó tr·ª£ nhi·ªÅu schemas ƒë·ªÉ extract d·ªØ li·ªáu h∆°n.

### C√°ch ngƒÉn ch·∫∑n site Scraping:

B·∫°n mu·ªën ngƒÉn ch·∫∑n m·ªôt c√¥ng c·ª• ƒÉn c·∫Øp t√†i s·∫£n tr√≠ tu·ªá c·ªßa m√¨nh c√≥ th·ªÉ s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c ph√°t hi·ªán c√°c Scraping bot v√† gi·∫£m thi·ªÉu vi·ªác truy v·∫•n d·ªØ li·ªáu

- S·ª≠ d·ª•ng c√¥ng c·ª• ph√¢n t√≠ch
- Tri·ªÉn khai c√°c challenge-based ƒë·ªÉ ƒë√°nh gi√° h√†nh vi c·ªßa ng∆∞·ªùi d√πng n·∫øu h·ªó tr·ª£ cookie v√† javascript.
- L·ª±a ch·ªçn h√†nh vi ti·∫øp c·∫≠n d·ªØ li·ªáu
- S·ª≠ d·ª•ng robots.txt ƒë·ªÉ b·∫£o v·ªá website tr∆∞·ªõc scraping bot ( h∆∞·ªõng d·∫´n c√°c con bot th·ª±c hi·ªán theo rules ƒë·ªãnh s·∫µn ). Tuy nhi√™n ph∆∞∆°ng ph√°p n√†y kh√¥ng ƒë∆∞·ª£c 

![Web Scraping](https://boxxv.github.io/img/2023/0006f3f6-1ea1-4413-baa0-58a9862661f9.webp "Web Scraping")


# Crawl data - c√†o d·ªØ li·ªáu c√≥ g√¨ kh√≥?

Vai tr√≤ c·ªßa d·ªØ li·ªáu th√¨ ch√∫ng ta kh√¥ng c·∫ßn b√†n lu·∫≠n n·ªØa. H√¥m nay m√¨nh s·∫ª chia s·∫ª m·ªôt v√†i ph∆∞∆°ng ph√°p v√† kh√≥ khƒÉn khi c√†o d·ªØ li·ªáu (crawl data) t·ª´ nh·ªØng ph∆∞∆°ng ph√°p, c√¥ng c·ª• m√¨nh ƒë√£ ·ª©ng d·ª•ng v√† m·ªôt s·ªë v·∫•n ƒë·ªÅ g·∫∑p ph·∫£i trong qu√° tr√¨nh l√†m lu·∫≠n vƒÉn. (c√≥ 2 kh√°i ni·ªám l√† data crawling v√† data scraping nh∆∞ng m√¨nh ch·ªâ n√≥i n√¥n na l√† thu th·∫≠p d·ªØ li·ªáu, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc th√™m ƒë·ªÉ ph√¢n bi·ªát)

C√†o ·ªü d·ªØ li·ªáu ·ªü ƒë√¢y m√¨nh ƒë·ªÅ c·∫≠p l√† d√πng m·ªôt c√¥ng c·ª• (tool) ƒë·ªÉ ƒëi thu th·∫≠p d·ªØ li·ªáu ·ªü m·ªôt s·ªë website m√† ch√∫ng ta c·∫ßn, ƒë∆°n thu·∫ßn c≈©ng ch·ªâ l√† g·ªüi m·ªôt request HTTP/HTTPS tr·ª±c ti·∫øp ho·∫∑c d√πng m·ªôt browser driver truy c·∫≠p ƒë·∫øn trang ƒë√≠ch ƒë·ªÉ l·∫•y n·ªôi dung trang v·ªÅ r·ªìi ti·∫øn h√†nh parse n·ªôi dung ƒë·ªÉ l·∫•y d·ªØ li·ªáu. H·∫ßu h·∫øt c√°c trang web ƒë·ªÅu kh√¥ng th·ªÉ ngƒÉn c·∫•m vi·ªác bot gh√© thƒÉm v√¨ trong ƒë√≥ c√≥ bot c·ªßa c√°c search engine nh∆∞ google, bing,‚Ä¶ tuy nhi√™n h·ªç c≈©ng kh√¥ng th·ªÉ n√†o cho ph√©p truy c·∫≠p th·ªèa m√°i v√¨ ƒëi·ªÅu n√†y l√†m gi·∫£m hi·ªáu nƒÉng ho·∫∑c th·∫≠m ch√≠ s·∫≠p c·∫£ server. Ch√≠nh v√¨ v·∫≠y ƒëa s·ªë c√°c website ƒë·ªÅu quy ƒë·ªãnh v√† t√¨m c√°ch h·∫°n ch·∫ø, ngƒÉn ch·∫∑n vi·ªác crawler qu√° m·ª©c, th·∫≠m ch√≠ c√≥ c·∫£ b·∫´y (traps) ƒë·ªÉ ch·∫∑n crawler khi·∫øn cho vi·ªác thu th·∫≠p d·ªØ li·ªáu c·ªßa ch√∫ng ta c≈©ng g·∫∑p kh√¥ng √≠t kh√≥ khƒÉn.

Tr∆∞·ªõc h·∫øt m√¨nh s·∫Ω gi·ªõi thi·ªáu qua m·ªôt s·ªë `tool`/`lib`/`framework` ph·ªï bi·∫øn ƒë·ªÉ th·ª±c hi·ªán thu th·∫≠p d·ªØ li·ªáu, m·∫∑c d√π vi·ªác c√†o d·ªØ li·ªáu ch·ªâ ƒë∆°n thu·∫ßn l√† g·ªüi request ƒë·ªÉ l·∫•y n·ªôi dung nh∆∞ng b·∫°n c≈©ng n√™n d√πng th∆∞ vi·ªán s·∫µn c√≥ ƒë·ªÉ thu th·∫≠p (tr·ª´ khi c√°c b·∫°n mu·ªën ph√°t tri·ªÉn 1 th∆∞ vi·ªán m·ªõi) thay v√¨ t·ª± g·ªüi request b·∫±ng th∆∞ vi·ªán HTTP trong c√°c ng√¥n ng·ªØ s·∫µn c√≥ v√¨ c√°c b·∫°n s·∫Ω ph·∫£i handle r·∫•t nhi·ªÅu th·ª© t·ª´ ƒëa lu·ªìng, ki·ªÉm so√°t request, parsing,‚Ä¶ r·∫•t t·ªën th·ªùi gian ƒë·ªÉ vi·∫øt l·∫°i. S·ª≠ d·ª•ng c√°c th∆∞ vi·ªán s·∫µn c√≥ th√¨ b·∫°n c≈©ng kh√¥ng c·∫ßn lo v·ªÅ kh·∫£ nƒÉng m·ªü r·ªông, t√πy bi·∫øn c·ªßa m√¨nh, c√°c th∆∞ vi·ªán ƒëa s·ªë ƒë√£ thi·∫øt k·∫ø theo ki·∫øn tr√∫c m·ªü cung c·∫•p c√°c `middlewares`, `pipelines` cho ng∆∞·ªùi d√πng t√πy bi·∫øn.

|  | Scrapy | Selenium |
| -- | -- | -- |
| Advantages | B·∫•t ƒë·ªìng b·ªô ch√≠nh l√† th·ª© gi√∫p cho scrapy c√≥ hi·ªáu nƒÉng tuy·ªát v·ªùi. S·ª≠ d·ª•ng r·∫•t √≠t RAM, CPU. T√†i li·ªáu ƒë·∫ßy ƒë·ªß, plugins r·∫•t nhi·ªÅu. Thi·∫øt k·∫ø theo m·ªôt ki·∫øn tr√∫c kh√° t·ªët, dev c√≥ th·ªÉ d·ªÖ d√†ng t√πy ch·ªânh middlewares, pipelines v√† th√™m c√°c function t√πy √Ω. | D·ªÖ ti·∫øp c·∫≠n cho beginer. C√≥ th·ªÉ l·∫•y ƒë∆∞·ª£c n·ªôi dung trang render b·∫±ng javascript. C√≥ th·ªÉ thao t√°c nh∆∞ m·ªôt ng∆∞·ªùi d√πng |
| Disadvantages | H∆°i ph·ª©c t·∫°p cho beginer. Qu√° d∆∞ th·ª´a ch·ª©c nƒÉng n·∫øu ch·ªâ d√πng cho 1 project nh·ªè v√† ƒë∆°n gi·∫£n. Kh√¥ng th·ªÉ l·∫•y n·ªôi dung trang ƒë∆∞·ª£c render b·∫±ng js, tuy nhi√™n ch√∫ng ta c√≥ th·ªÉ k·∫øt h·ª£p v·ªõi Splash. | Ti√™u t·ªën nhi·ªÅu t√†i nguy√™n v√¨ n√≥ c·∫ßn ƒë·∫øn m·ªôt browser driver (t∆∞·ªüng t∆∞·ª£ng nh∆∞ b·∫°n m·ªü 1 tab chrome th√¨ s·∫Ω t·ªën bao nhi√™u RAM, CPU). R·∫•t ch·∫≠m, n√™n selenium kh√¥ng ph√π h·ª£p v·ªõi m·ªôt project c√†o d·ªØ li·ªáu l·ªõn. |
| Homepage | [scrapy.org](https://scrapy.org) | [selenium.dev](https://www.selenium.dev) |

|  | Cheerio | Puppeteer |
| -- | -- | -- |
| Advantages | H·ªó tr·ª£ parse DOM gi·ªëng nh∆∞ jquery. B·∫•t ƒë·ªìng b·ªô, kh√° nhanh | Gi·ªëng nh∆∞ selenium, puppeteer c≈©ng s·ª≠ d·ª•ng browser driver ƒë·ªÉ l·∫•y n·ªôi dung trang n√™n c√≥ th·ªÉ l·∫•y ƒë∆∞·ª£c n·ªôi dung c√°c trang render b·∫±ng js v√† thao t√°c nh∆∞ m·ªôt ng∆∞·ªùi d√πng. |
| Disadvantages | Ch·ªâ ƒë∆°n thu·∫ßn l√† tr√¨nh ph√¢n t√≠ch (parser). Kh√¥ng th·ªÉ l·∫•y n·ªôi dung trang ƒë∆∞·ª£c render b·∫±ng js | Ti√™u t·ªën RAM, CPU. Ch·∫≠m |
| Homepage | [cheerio.js.org](https://cheerio.js.org) | [pptr.dev](https://pptr.dev) |

#### [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) (BS4)

Beautiful Soup (BS4) l√† m·ªôt th∆∞ vi·ªán ph√¢n t√≠ch c√∫ ph√°p c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c parsers kh√°c nhau t·ª´ ƒë√≥ c√≥ th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c t√†i li·ªáu HTML v√† XML m·ªôt c√°ch d·ªÖ d√†ng. V·ªÅ m·∫∑c ƒë·ªãnh, Beautiful Soup s·ª≠ d·ª•ng parser c∆° b·∫£n c·ªßa Python. M·∫∑c d√π kh√° linh ho·∫°t v√† d·ªÖ s·ª≠ d·ª•ng, parser n√†y l√† c√≥ hi·ªáu nƒÉng kh√° k√©m do t·ªëc ƒë·ªô x·ª≠ l√Ω kh√° ch·∫≠m. Tin t·ªët l√† b·∫°n ho√†n to√†n c√≥ th·ªÉ ho√°n ƒë·ªïi tr√¨nh ph√¢n t√≠ch c√∫ ph√°p c·ªßa n√≥ b·∫±ng m·ªôt tr√¨nh ph√¢n t√≠ch c√∫ ph√°p nhanh h∆°n n·∫øu b·∫°n c·∫ßn c·∫£i thi·ªán nhi·ªÅu t·ªëc ƒë·ªô c·ªßa ·ª©ng d·ª•ng.

Sau khi ph√¢n t√≠ch c√°c HTML c≈©ng nh∆∞ XML ƒë·∫ßu v√†o, Beautiful Soup cho ph√©p ch√∫ng ta d·ªÖ d√†ng di chuy·ªÉn, t√¨m ki·∫øm, thay ƒë·ªïi c≈©ng nh∆∞ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√¢y c√∫ ph√°p. C√∫ ph√°p r√µ r√†ng linh ho·∫°t t∆∞∆°ng t·ª± c√°ch ch√∫ng ta t∆∞∆°ng t√°c v·ªõi DOM b·∫±ng c√°c th∆∞ vi·ªán JavaScript l√† m·ªôt trong nh·ªØng l√Ω do khi·∫øn Beautiful Soup tr·ªü th√†nh m·ªôt trong nh·ªØng c√¥ng c·ª• ph·ªï bi·∫øn nh·∫•t cho vi·ªác thu th·∫≠p d·ªØ li·ªáu web, b√™n c·∫°nh s·ª± m·∫°nh m·∫Ω c·ªßa n√≥.

#### Selenium

Selenium l√† m·ªôt trong nh·ªØng c√¥ng c·ª• ki·ªÉm th·ª≠ ph·∫ßn m·ªÅm t·ª± ƒë·ªông m√£ ngu·ªìn m·ªü m·∫°nh nh·∫•t hi·ªán nay cho vi·ªác ki·ªÉm th·ª≠ ·ª©ng d·ª•ng Web. Selenium script c√≥ th·ªÉ ch·∫°y ƒë∆∞·ª£c tr√™n h·∫ßu h·∫øt c√°c tr√¨nh duy·ªát nh∆∞ IE, Mozilla FireFox, Chrome, Safari, Opera; v√† h·∫ßu h·∫øt c√°c h·ªá ƒëi·ªÅu h√†nh nh∆∞ Windows, Mac, Linux. V·ªÅ c∆° b·∫£n m√† n√≥i, qu√° tr√¨nh scraping c≈©ng t∆∞∆°ng t·ª± nh∆∞ qu√° tr√¨nh ki·ªÉm th·ª≠ ·ª©ng d·ª•ng t·ª± ƒë·ªông b·ªüi ch√∫ng ƒë·ªÅu th·ª±c hi·ªán m·ªôt chu·ªói thao t√°c t∆∞∆°ng t√°c v·ªõi c√°c trang web m·ªôt c√°ch t·ª± ƒë·ªông v√† li√™n t·ª•c. B·ªüi v·∫≠y, Selenium th∆∞·ªùng xuy√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng nh·∫•t l√† khi c·∫ßn thu th·∫≠p t·ª´ c√°c trang web SPA - th·ª© m√† kh√≥ c√≥ th·ªÉ thu th·∫≠p ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ n√≥ n·∫øu nh∆∞ ph·∫ßn m√£ JavaScript c·ªßa ch√∫ng kh√¥ng ƒë∆∞·ª£c th·ª±c thi.

#### Scrapy

V·ªÅ m·∫∑t k·ªπ thu·∫≠t, Scrapy kh√¥ng ph·∫£i m·ªôt th∆∞ vi·ªán m√† l√† m·ªôt framework ph·ª•c v·ª• m·ª•c ƒë√≠ch thu th·∫≠p d·ªØ li·ªáu. ƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng n√≥ ƒë·ªÉ qu·∫£n l√Ω c√°c y√™u c·∫ßu, duy tr√¨ c√°c phi√™n c·ªßa ng∆∞·ªùi d√πng, theo d√µi chuy·ªÉn h∆∞·ªõng v√† x·ª≠ l√Ω c√°c pipelines ƒë·∫ßu ra. N√≥ c≈©ng c√≥ nghƒ©a l√† b·∫°n c√≥ th·ªÉ ho√°n ƒë·ªïi c√°c m√¥-ƒëun ri√™ng l·∫ª v·ªõi c√°c th∆∞ vi·ªán duy·ªát web Python kh√°c. V√≠ d·ª•: n·∫øu b·∫°n c·∫ßn ch√®n Selenium ƒë·ªÉ qu√©t c√°c trang web ƒë·ªông, b·∫°n c√≥ th·ªÉ l√†m ƒëi·ªÅu ƒë√≥.

H·∫ßu h·∫øt c√°c ng√¥n ng·ªØ l·∫≠p tr√¨nh ƒë·ªÅu c√≥ nh·ªØng th∆∞ vi·ªán h·ªó tr·ª£ thu th·∫≠p d·ªØ li·ªáu, tuy nhi√™n `Python` s·∫Ω l√† ng√¥n ng·ªØ  m√† m√¨nh g·ª£i √Ω c√°c b·∫°n n√™n ch·ªçn cho d·ª± √°n thu th·∫≠p d·ªØ li·ªáu c·ªßa m√¨nh, `Scrapy` l√† m·ªôt framework trong python h·ªó tr·ª£ thu th·∫≠p d·ªØ li·ªáu c·ª±c m·∫°nh, h∆°n n·ªØa python c√≥ h·ªó tr·ª£ kh√° nhi·ªÅu th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu.

### Nh·∫≠p m√¥n thu th·∫≠p d·ªØ li·ªáu

Ki·∫øn tr√∫c chung c·ªßa m·ªôt crawler s·∫Ω g·ªìm 3 ph·∫ßn:
1. queue ch·ª©a URL
2. downloader
3. parser

Lu·ªìng ho·∫°t ƒë·ªông s·∫Ω di·ªÖn ra nh∆∞ sau:
- Cung c·∫•p m·ªôt URL ƒë·ªÉ start (ho·∫∑c m·ªôt list URL)
- Downloader ti·∫øn h√†nh t·∫£i xu·ªëng n·ªôi dung trang
- Parser r√∫t tr√≠ch d·ªØ li·ªáu (store n·∫øu c·∫ßn) v√† ƒë·ªìng th·ªùi r√∫t tr√≠ch ra URL k·∫ø ti·∫øp v√† th√™m v√†o queue URL
- Qu√° tr√¨nh s·∫Ω l·∫∑p l·∫°i cho ƒë·∫øn h·∫øt URL trong queue

![Web Scraping](https://boxxv.github.io/img/2023/crawler_simple.png "Web Scraping")

ƒê·ªÉ l√†m quen v·ªõi vi·ªác thu th·∫≠p d·ªØ li·ªáu, m√¨nh khuy√™n c√°c b·∫°n n√™n l√†m qua 10 b√†i th·ª±c h√†nh tr√™n trang [Scrapingclub](https://scrapingclub.com) (Learn Web Scraping Using Python For Free) theo b·∫•t k·ª≥ th∆∞ vi·ªán h·ªó tr·ª£ thu th·∫≠p d·ªØ li·ªáu n√†o b·∫°n mu·ªën, solutions th√¨ m√¨nh c≈©ng ƒë√£ l√†m t·ª´ l√∫c m√¨nh h·ªçc c∆° b·∫£n [https://github.com/lhsang/Spiders](https://github.com/lhsang/Spiders) (s·ª≠ d·ª•ng scrapy) c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o.

V·ªÅ v·∫•n ƒë·ªÅ thu th·∫≠p th√¥ng tin ƒë·ªÉ tr√°nh vi ph·∫°m c√°c ti√™u chu·∫©n, quy ƒë·ªãnh th√¨ c√°c b·∫°n n√™n ph√¢n t√≠ch file `http://domain.com/robots.txt` tr∆∞·ªõc khi c√†o, file robots.txt s·∫Ω ƒë·ªãnh quy cho bi·∫øt Crawler c·ªßa b·∫°n ƒë∆∞·ª£c truy c·∫≠p nh·ªØng trang n√†o, kh√¥ng ƒë∆∞·ª£c truy c·∫≠p trang n√†o v√† th·ªùi gian delay m·ªói request. Ngo√†i ra user-agent l√† m·ªôt header b·∫°n c√≥ th·ªÉ t√πy √Ω, tuy nhi√™n v·ªÅ v·∫•n ƒë·ªÅ ƒë·∫°o ƒë·ª©c ngh·ªÅ nghi·ªáp c√°c b·∫°n kh√¥ng n√™n fake gi√° tr·ªã n√†y.

Ph·∫ßn ti·∫øp theo m√¨nh s·∫Ω n√≥i v·ªÅ m·ªôt s·ªë kh√≥ khƒÉn ƒë√£ g·∫∑p v√† gi·∫£i ph√°p trong qu√° tr√¨nh thu th·∫≠p d·ªØ li·ªáu ph·ª•c v·ª• cho lu·∫≠n vƒÉn t·ªët nghi·ªáp:

- C√°c trang h·∫°n ch·∫ø s·ªë l∆∞·ª£ng truy c·∫≠p trong m·ªôt kho·∫£ng th·ªùi gian: ƒë·ªÉ tr√°nh vi·ªác m·ªôt IP l√†m qu√° t·∫£i server, c√°c trang th∆∞·ªùng ph·∫£i gi·ªõi h·∫°n s·ªë request c·ªßa m·ªôt IP trong m·ªôt ph√∫t (th∆∞·ªùng s·∫Ω h·ªç s·∫Ω cho bi·∫øt th·ªùi gian deplay m·ªói request trong file robots.txt), c√≥ m·ªôt s·ªë l∆∞·ª£ng l·ªõn trang c·∫ßn thu th·∫≠p th√¨ m√¥i ph√∫t v√†i request th√¨ qu√° √≠t cho nhu c·∫ßu c·ªßa m√¨nh v√† th·∫≠m ch√≠ n·∫øu g·ª≠i nhi·ªÅu h∆°n quy ƒë·ªãnh, crawler c√≤n c√≥ th·ªÉ b·ªã ban trong v√†i ph√∫t. Gi·∫£i ph√°p l√† m√¨nh ƒë√£ s·ª≠ d·ª•ng th√™m proxy server, gi√° proxy c≈©ng kh√¥ng qu√° m·∫Øc (t·∫ßm $0.4 IP/th√°ng, khuy√™n c√°c b·∫°n kh√¥ng n√™n mua c·ªßa c√°c nh√† cung c·∫•p t·ª´ Vi·ªát Nam - ng∆∞·ªùi t·ª´ng tr·∫£i), m·ªói request m√¨nh s·∫Ω ƒë·ªïi IP li√™n t·ª•c th√¨ s·∫Ω tr√°nh ƒë∆∞·ª£c ban IP. N·∫øu kh√¥ng c·∫ßn thi·∫øt ph·∫£i ƒë·ªïi IP th√¨ ban c√≥ th·ªÉ tƒÉng th·ªùi gian DELAY_REQUEST ƒë·ªÉ c√°ch bi·ªát c√°c request, gi·∫£m CONCURRENT_REQUESTS (s·ªë request ƒë·ªìng th·ªùi) v√† c√≥ th·ªÉ cheat nh·∫π user-agent b·∫•t ch·∫•p ƒë·∫°o ƒë·ª©c :))
- N·ªôi dung trang render b·∫±ng Javascript: v√¨ nhu c·∫ßu m√¨nh crawl nhi·ªÅu n√™n m√¨nh ch·ªçn Scrapy, tuy nhi√™n scrapy l·∫°i kh√¥ng h·ªó tr·ª£ l·∫•y d·ªØ li·ªáu ·ªü c√°c trang render b·∫±ng js (Ajax, React,‚Ä¶) ƒë·ªÉ bi·∫øt r·∫±ng trang n√†y c√≥ render b·∫±ng js ra n·ªôi dung kh√¥ng, b·∫°n ch·ªâ c·∫ßn Ctrl+U r·ªìi xem c√≥ n·ªôi dung html nh∆∞ hi·ªÉn th·ªã kh√¥ng, hay ch·ªâ l√† m·ªôt th·∫ª body r·ªìi js ch√®n v√†o sau. Nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p scrapy c√≥ th·ªÉ s·ª≠ d·ª•ng k√®m v·ªõi headless browser nh∆∞ Splash ƒë·ªÉ ch·ªù trang web render ra n·ªôi dung v√† cookie, vi·ªác n√†y l√†m t·ªën th√™m m·ªôt √≠t th·ªùi gian ch·ªù nh∆∞ng v·∫´n nhanh h∆°n c√°c l·ª±a ch·ªçn kh√°c scrapy.
- C·∫•u tr√∫c trang thay ƒë·ªïi: ƒë√¥i l√∫c sites thay ƒë√¥·ªâ c·∫•u tr√∫c (HTML tags thay ƒë·ªïi), ch√∫ng ta ph·∫£i x√°c ƒë·ªãnh ƒë√∫ng th·∫ª th√¨ m·ªõi l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu. N√™n c√†i ƒë·∫∑t cho crawler c∆° ch·∫ø ph√°t hi·ªán c·∫•u tr√∫c thay ƒë·ªïi v√† th√¥ng b√°o ƒë·ªÉ ch√∫ng ta bi·∫øt v√† ch·ªânh s·ª≠a ho·∫∑c √°p d·ª•ng c·∫•u tr√∫c m·ªõi ƒë·ªÉ parse ƒë√∫ng d·ªØ li·ªáu.
- Required ƒë·ªß cookie, headers: ƒëa s·ªë c√°c trang ƒë·ªÅu y√™u c·∫ßu m·ªôt s·ªë headers v√† cookie l√† ph·∫£i c√≥ trong request, ch√∫ng ta c√≥ th·ªÉ d√πng Chrome DevTools ƒë·ªÉ xem c√°c header v√† cookie n√†y, tuy nhi√™n ·ªü nhi·ªÅu trang headers, cookie n√†y kh√¥ng ƒë∆∞·ª£c set ngay t·ª´ ƒë·∫ßu m√† trong qu√° tr√¨nh request s·∫Ω g·ªüi request ƒë·∫øn m·ªôt URL kh√°c ƒë·ªÉ l·∫•y th√¥ng tin headers, cookie ho·∫∑c ngay ƒë·ªãa ch·ªâ URL c·ªßa b·∫°n nh∆∞ng l·∫ßn ƒë·∫ßu l√† ƒë·ªÉ l·∫•y headers, cookie l·∫ßn sau m·ªõi l·∫•y n·ªôi dung (tr∆∞·ªùng h·ª£p n√†y, n·∫øu kh√¥ng c√≥ ƒë·ªß headers server s·∫Ω bu·ªôc crawler request v√¥ h·∫°n). Gi·∫£i ph√°p l√† ch√∫ng ta ph·∫£i bi·∫øt quan s√°t m√† l·∫•y headers, cookie ph√π h·ª£p ƒë·ªÉ g·∫Øn v√†o request th√¥i =))
- B·∫•t ƒë·ªìng b·ªô v√† multithread v·∫´n ch∆∞a ƒë·ªß: m·ªói ng√†y m√¨nh ph·∫£i g·ªüi h∆°n v√†i ch·ª•c tri·ªáu request, scrapy h·ªó tr·ª£ b·∫•t ƒë·ªìng b·ªô, tuy nhi√™n m·ªôt process ch∆∞a ƒë·ªß ƒë√°p ·ª©ng nhu c·∫ßu l·ªõn nh∆∞ v·∫≠y trong m·ªôt ng√†y, gi·∫£i ph√°p l√† tƒÉng s·ªë process l√™n (c√≥ th·ªÉ cho ch·∫°y ·ªü nhi·ªÅu server), li√™n quan ƒë·∫øn v·∫•n ƒë·ªÅ x·ª≠ l√Ω song song c√°c b·∫°n ph·∫£i t√≠nh to√°n ƒë·ªÉ chia URL ra cho c√°c process h·ª£p l√Ω nh·∫•t.
- L∆∞u tr·ªØ d·ªØ li·ªáu: t√πy nhu c·∫ßu b·∫°n s·∫Ω ch·ªçn h·ªá qu·∫£n tr·ªã c∆° s·ªü d·ªØ li·ªáu ph√π h·ª£p, v·ªõi project c·ªßa m√¨nh v√¨ nhu c·∫ßu l∆∞u tr·ªØ l·ªõn (h∆°n 11 tri·ªáu record m·ªói ng√†y ƒë·ªï v√†o database) v√† c·∫ßn t·ªëc ƒë·ªô truy v·∫´n nhanh th√¨ m√¨nh ch·ªçn mongodb. MongoDB thu·ªôc lo·∫°i NoSQL l∆∞u tr·ªØ theo d·∫°ng document (BSON), schema linh ho·∫°t, kh√¥ng ph·∫£i join, k·∫øt h·ª£p v·ªõi ƒë√°nh indexes th√¨ t·ªëc ƒë·ªô kh√° l√† nhanh (d·ªØ li·ªáu 1 t·ª∑ records m√¨nh c√≥ th·ªÉ truy v·∫•n d∆∞·ªõi 1s) h∆°n n·ªØa mongodb c√≤n thi·∫øt k·∫ø ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu ph√¢n t√°n n√™n c√≥ th·ªÉ sharding hay replication ƒë·ªÉ m·ªü r·ªông, tƒÉng hi·ªáu nƒÉng v√† ƒë·∫£m b·∫£o t√≠nh available cho h·ªá th·ªëng. V·∫•n ƒë·ªÅ l∆∞u xu·ªëng li√™n t·ª•c c≈©ng c√≥ th·ªÉ qu√° t·∫£i database, b·∫°n c√≥ th·ªÉ cache t·∫°m m·ªôt n∆°i r·ªìi insert_many thay v√¨ insert_one.

# X√¢y d·ª±ng s∆° b·ªô m·ªôt h·ªá th·ªëng crawler

## 1. L·∫•y xpath nh∆∞ th·∫ø n√†o?

ƒê·ªÉ l·∫•y ƒë∆∞·ª£c m·ªôt ƒëo·∫°n m√£ xpath nh∆∞ th·∫ø n√†y:

```html
//*[@id="aspnetForm"]/div[5]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/h2/a
```

m√¨nh hay d√πng extension [Xpath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl). T·∫•t nhi√™n m√¨nh c√≥ clone repo c·ªßa extension n√†y v·ªÅ v√† custome l·∫°i ƒë·ªÉ cho thu·∫≠n ti·ªán vi·ªác l·∫•y v√† insert template v√†o h·ªá th·ªëng. Trong 1 website, 1 xpath c√≥ th·ªÉ ƒë√∫ng v·ªõi page n√†y nh∆∞ng l·∫°i kh√¥ng ƒë√∫ng v·ªõi page kia n√™n b·∫°n c·∫ßn t·ªëi ∆∞u xpath ƒë∆∞·ª£c suggest t·ª´ Xpath Helper sao cho ph√π h·ª£p v·ªõi nhi·ªÅu page nh·∫•t.

## 2. H·ªá th·ªëng qu·∫£n l√Ω template

### a, Backend

C√≥ th·ªÉ d√πng lu√¥n [Flask](https://flask.palletsprojects.com/en/2.3.x/) ƒë·ªÉ t·∫°o h·ªá th·ªëng api v·ªõi c√°c ch·ª©c nƒÉng th√™m, x√≥a, s·ª≠a, generate file, start, stop m·ªôt spider cho ƒë·ª° m·∫•t c√¥ng h·ªçc th√™m th·ª© kh√°c. Flask c·ªßa python d√πng th√¨ max nhanh v√† ƒë∆°n gi·∫£n, ch·ªâ c·∫ßn import l√† s√†i th√¥i. N√™n d√πng databases NoSQL ƒë·ªÉ l∆∞u tr·ªØ th√¥ng tin c√°c template v√¨ t√≠nh linh ƒë·ªông c·ªßa ch√∫ng.

### b, Frontend

React ho·∫∑c Angularjs xx . M√¨nh l√†m backend l√† ch√≠nh n√™n c≈©ng kh√¥ng quan t√¢m l·∫Øm, c·ª© d·ªÖ d√πng, nhi·ªÅu support th√¨ m√¨nh s√†i th√¥i. Tr∆∞·ªõc th√¨ m√¨nh c√≥ d√πng React, nh∆∞ng gi·ªù chuy·ªÉn qua Angularjs xx r·ªìi (xx l√† version c·ªßa Angular nh√© üòÑ)

### c, Qu·∫£n l√Ω c√°c m√°y crawler

Khi h·ªá th·ªëng c·ªßa b·∫°n m·ªü r·ªông c√≥ 2K, 3K site c·∫ßn crawl m·ªói ng√†y th√¨ b·∫°n s·∫Ω c·∫ßn ph·∫£i c√≥ nhi·ªÅu h∆°n 1 m√°y crawler. L√∫c n√†y c·∫ßn th√™m m·ªôt vi·ªác l√† qu·∫£n l√Ω c√°c m√°y crawler sao cho ch√∫ng ch·∫°y t·ªëi ƒëa c√¥ng su·∫•t c√≥ th·ªÉ v√† kh√¥ng x·∫£y ra t√¨nh tr·∫°ng 1 site ƒë∆∞·ª£c crawl ·ªü 2 m√°y kh√°c nhau. L√∫c n√†y b·∫°n c√≥ th·ªÉ nghƒ© t·ªõi Celery, n√≥ s·∫Ω gi√∫p b·∫°n ƒë·ªìng b·ªô gi·ªØa c√°c m√°y crawler, qu·∫£n l√Ω d·ªÖ h∆°n v√† c≈©ng tƒÉng hi·ªáu su·∫•t c·ªßa server h∆°n. Ho·∫∑c to tay th√¨ c√≥ th·ªÉ t·ª± code c≈©ng ƒë∆∞·ª£c, v√¨ v·ªÅ c∆° b·∫£n th√¨ m·ªói m√°y c√≥ 1 c·∫•u h√¨nh ri√™ng, c√¥ng su·∫•t ri√™ng n√™n c·ª© n√©m ri√™ng cho 1 file config, cho ch√∫ng sync ƒë∆∞·ª£c v·ªõi m·ªôt th·∫±ng master n√†o ƒë·∫•y r·ªìi t·ª´ th·∫±ng master ch·ªâ ƒë·∫°o th·∫±ng n√†o l√†m g√¨ qua api th√¥i.

### d, Gi√°m s√°t hi·ªáu nƒÉng c·ªßa h·ªá th·ªëng

M√¨nh ƒë√£ d√πng [Datadog](https://viblo.asia/p/datadog-cai-dat-va-cau-hinh-cho-rails-application-vyDZOW87Zwj) ƒë·ªÉ tracking xem m·ªôt ng√†y h·ªá th·ªëng m√¨nh crawl ƒë∆∞·ª£c bao nhi√™u item, so s√°nh v·ªõi c√°c ng√†y tr∆∞·ªõc ƒë√≥. Khi c√≥ 1 m√°y crawler lƒÉn ra ch·∫øt s·∫Ω c√≥ mail b√°o t·ª´ datadog, khi hight CPU..v.v

# Thu th·∫≠p d·ªØ li·ªáu b·∫±ng c√°c ng√¥n ng·ªØ kh√°c nhau.



# Crawl Data v·ªõi Chrome Extension

- [Web Scraper](https://chrome.google.com/webstore/detail/web-scraper-free-web-scra/jnhgnonknehpejjnehehllkliplmbmhn?hl=en)
- [Web Scraper intro tutorial](https://youtu.be/n7fob_XVsbY)
- App [HttpCanary](https://m.apkpure.com/vn/httpcanary-%E2%80%94-http-sniffer-capture-analysis/com.guoshi.httpcanary) ƒë·ªÉ xem ph·∫ßn network c·ªßa api

# Thu th·∫≠p d·ªØ li·ªáu webb·∫±ng c√°c ng√¥n ng·ªØ kh√°c nhau

- [Python](#python)
- [Java](#java)
- [C#](#c)
- [JavaScript](#javascript)
- [PHP](#php)
- [C++](#c-1)
- [C](#c-2)
- [Ruby](#ruby)
- [Rust](#rust)
- [R](#r)
- [Erlang](#erlang)
- [Perl](#perl)
- [Go](#go)
- [Scala](#scala)

## Python 
* [Scrapy](https://github.com/scrapy/scrapy) - Framework qu√©t m√†n h√¨nh v√† thu th·∫≠p d·ªØ li·ªáu web c·∫•p cao nhanh ch√≥ng.
    * [django-dynamic-scraper](https://github.com/holgerd77/django-dynamic-scraper) - T·∫°o Scrapy Scraper th√¥ng qua giao di·ªán qu·∫£n tr·ªã Django.
    * [Scrapy-Redis](https://github.com/rolando/scrapy-redis) - C√°c th√†nh ph·∫ßn (components) d·ª±a tr√™n Redis cho Scrapy.
    * [scrapy-cluster](https://github.com/istresearch/scrapy-cluster) - S·ª≠ d·ª•ng Redis v√† Kafka ƒë·ªÉ t·∫°o c·ª•m thu th·∫≠p d·ªØ li·ªáu ph√¢n t√°n theo y√™u c·∫ßu.
    * [distribute_crawler](https://github.com/gnemoug/distribute_crawler) - S·ª≠ d·ª•ng Scrapy, Redis, Mongodb,graphite ƒë·ªÉ t·∫°o ra m·ªôt con nh·ªán ph√¢n t√°n.
* [pyspider](https://github.com/binux/pyspider) - M·ªôt h·ªá th·ªëng spider m·∫°nh m·∫Ω.
* [CoCrawler](https://github.com/cocrawler/cocrawler) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒëa nƒÉng ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng c√°c c√¥ng c·ª• hi·ªán ƒë·∫°i v√† ƒë·ªìng th·ªùi.
* [cola](https://github.com/chineking/cola) - Framework thu th·∫≠p th√¥ng tin ph√¢n t√°n.
* [Demiurge](https://github.com/matiasb/demiurge) - Micro-framework qu√©t d·ª±a tr√™n PyQuery.
* [Scrapely](https://github.com/scrapy/scrapely) - Th∆∞ vi·ªán qu√©t m√†n h√¨nh HTML thu·∫ßn Python.
* [feedparser](http://pythonhosted.org/feedparser/) - Tr√¨nh ph√¢n t√≠ch c√∫ ph√°p ngu·ªìn c·∫•p d·ªØ li·ªáu ph·ªï qu√°t.
* [you-get](https://github.com/soimort/you-get) -  Tr√¨nh t·∫£i xu·ªëng Dumb scrapes trang web.
* [MechanicalSoup](https://github.com/hickford/MechanicalSoup) - Th∆∞ vi·ªán Python ƒë·ªÉ t·ª± ƒë·ªông h√≥a t∆∞∆°ng t√°c v·ªõi c√°c trang web.
* [portia](https://github.com/scrapinghub/portia) - Qu√©t h√¨nh ·∫£nh cho Scrapy.
* [crawley](https://github.com/jmg/crawley) - Framework thu th·∫≠p d·ªØ li·ªáu / thu th·∫≠p d·ªØ li·ªáu Pythonic d·ª±a tr√™n c√°c ho·∫°t ƒë·ªông I/O kh√¥ng ch·∫∑n.
* [RoboBrowser](https://github.com/jmcarp/robobrowser) - M·ªôt th∆∞ vi·ªán Pythonic ƒë∆°n gi·∫£n ƒë·ªÉ duy·ªát web m√† kh√¥ng c·∫ßn tr√¨nh duy·ªát web ƒë·ªôc l·∫≠p.
* [MSpider](https://github.com/manning23/MSpider) - M·ªôt con nh·ªán ƒë∆°n gi·∫£n, d·ªÖ d√†ng s·ª≠ d·ª•ng gevent v√† js render.
* [brownant](https://github.com/douban/brownant) - Framework tr√≠ch xu·∫•t d·ªØ li·ªáu web nh·∫π.
* [PSpider](https://github.com/xianhu/PSpider) - M·ªôt framework nh·ªán ƒë∆°n gi·∫£n trong Python3.
* [Gain](https://github.com/gaojiuli/gain) - Framework thu th·∫≠p d·ªØ li·ªáu web d·ª±a tr√™n asyncio cho m·ªçi ng∆∞·ªùi.
* [sukhoi](https://github.com/iogf/sukhoi) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web t·ªëi gi·∫£n v√† m·∫°nh m·∫Ω.
* [spidy](https://github.com/rivermont/spidy) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web d√≤ng l·ªánh ƒë∆°n gi·∫£n, d·ªÖ s·ª≠ d·ª•ng.
* [newspaper](https://github.com/codelucas/newspaper) - Tr√≠ch xu·∫•t si√™u d·ªØ li·ªáu tin t·ª©c, to√†n vƒÉn v√† b√†i vi·∫øt b·∫±ng Python 3
* [aspider](https://github.com/howie6879/aspider) - M·ªôt micro-framework qu√©t web kh√¥ng ƒë·ªìng b·ªô d·ª±a tr√™n asyncio.

## Java
* [ACHE Crawler](https://github.com/ViDA-NYU/ache) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web d·ªÖ s·ª≠ d·ª•ng ƒë·ªÉ t√¨m ki·∫øm theo t√™n mi·ªÅn c·ª• th·ªÉ.
* [Apache Nutch](http://nutch.apache.org/) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web c√≥ kh·∫£ nƒÉng m·ªü r·ªông cao, c√≥ kh·∫£ nƒÉng m·ªü r·ªông cao cho m√¥i tr∆∞·ªùng s·∫£n xu·∫•t.
    * [anthelion](https://github.com/yahoo/anthelion) - M·ªôt plugin d√†nh cho Apache Nutch ƒë·ªÉ thu th·∫≠p th√¥ng tin c√°c ch√∫ th√≠ch ng·ªØ nghƒ©a trong c√°c trang HTML.
* [Crawler4j](https://github.com/yasserg/crawler4j) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒë∆°n gi·∫£n v√† nh·∫π.
* [JSoup](http://jsoup.org/) - Qu√©t, ph√¢n t√≠ch, thao t√°c v√† l√†m s·∫°ch HTML.
* [websphinx](http://www.cs.cmu.edu/~rcm/websphinx/) - B·ªô x·ª≠ l√Ω d√†nh ri√™ng cho trang web ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin HTML.
* [Open Search Server](http://www.opensearchserver.com/) - T·∫≠p h·ª£p ƒë·∫ßy ƒë·ªß c√°c ch·ª©c nƒÉng t√¨m ki·∫øm. X√¢y d·ª±ng chi·∫øn l∆∞·ª£c l·∫≠p ch·ªâ m·ª•c c·ªßa ri√™ng b·∫°n. Tr√¨nh ph√¢n t√≠ch c√∫ ph√°p tr√≠ch xu·∫•t d·ªØ li·ªáu to√†n vƒÉn. Tr√¨nh thu th·∫≠p th√¥ng tin c√≥ th·ªÉ l·∫≠p ch·ªâ m·ª•c m·ªçi th·ª©.
* [Gecco](https://github.com/xtuhcy/gecco) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web nh·∫π d·ªÖ s·ª≠ d·ª•ng
* [WebCollector](https://github.com/CrawlScript/WebCollector) - Giao di·ªán ƒë∆°n gi·∫£n ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu tr√™n Web, b·∫°n c√≥ th·ªÉ thi·∫øt l·∫≠p tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒëa lu·ªìng trong v√≤ng ch∆∞a ƒë·∫ßy 5 ph√∫t.
* [Webmagic](https://github.com/code4craft/webmagic) - Framework thu th·∫≠p th√¥ng tin c√≥ th·ªÉ m·ªü r·ªông.
* [Spiderman](https://git.oschina.net/l-weiwei/spiderman) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒëa lu·ªìng, c√≥ th·ªÉ m·ªü r·ªông, c√≥ th·ªÉ m·ªü r·ªông.
    * [Spiderman2](http://git.oschina.net/l-weiwei/Spiderman2) - Framework thu th·∫≠p d·ªØ li·ªáu web ph√¢n t√°n, h·ªó tr·ª£ k·∫øt xu·∫•t js.
* [Heritrix3](https://github.com/internetarchive/heritrix3) -  D·ª± √°n tr√¨nh thu th·∫≠p d·ªØ li·ªáu web c√≥ ch·∫•t l∆∞·ª£ng l∆∞u tr·ªØ, c√≥ quy m√¥ web, c√≥ th·ªÉ m·ªü r·ªông
* [SeimiCrawler](https://github.com/zhegexiaohuozi/SeimiCrawler) - M·ªôt framework thu th·∫≠p th√¥ng tin ph√¢n t√°n, linh ho·∫°t.
* [StormCrawler](http://github.com/DigitalPebble/storm-crawler/) -  B·ªô s∆∞u t·∫≠p t√†i nguy√™n ngu·ªìn m·ªü ƒë·ªÉ x√¢y d·ª±ng tr√¨nh thu th·∫≠p d·ªØ li·ªáu web c√≥ ƒë·ªô tr·ªÖ th·∫•p, c√≥ th·ªÉ m·ªü r·ªông tr√™n Apache Storm
* [Spark-Crawler](https://github.com/USCDataScience/sparkler) - ƒêang ph√°t tri·ªÉn Apache Nutch ƒë·ªÉ ch·∫°y tr√™n Spark.
* [webBee](https://github.com/pkwenda/webBee) - M·ªôt con nh·ªán web DFS.
* [spider-flow](https://github.com/ssssssss-team/spider-flow) - M·ªôt framework nh·ªán tr·ª±c quan, t·ªët ƒë·∫øn m·ª©c b·∫°n `kh√¥ng c·∫ßn ph·∫£i vi·∫øt b·∫•t k·ª≥ m√£ n√†o` ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu trang web.


## C# 
* [ccrawler](http://www.findbestopensource.com/product/ccrawler) - ƒê∆∞·ª£c x√¢y d·ª±ng trong phi√™n b·∫£n C# 3.5. n√≥ ch·ª©a m·ªôt ph·∫ßn m·ªü r·ªông ƒë∆°n gi·∫£n c·ªßa tr√¨nh ph√¢n lo·∫°i n·ªôi dung web, c√≥ th·ªÉ ph√¢n t√°ch gi·ªØa c√°c trang web t√πy thu·ªôc v√†o n·ªôi dung c·ªßa ch√∫ng.
* [SimpleCrawler](https://github.com/lei-zhu/SimpleCrawler) - Spider ƒë∆°n gi·∫£n d·ª±a tr√™n bi·ªÉu th·ª©c ƒëa lu·ªìng, regluar.
* [DotnetSpider](https://github.com/zlzforever/DotnetSpider) - ƒê√¢y l√† m·ªôt spider ƒëa n·ªÅn t·∫£ng, nh·∫π ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi C#.
* [Abot](https://github.com/sjdirect/abot) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web C# ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ c√≥ t·ªëc ƒë·ªô v√† t√≠nh linh ho·∫°t.
* [Hawk](https://github.com/ferventdesert/Hawk) - C√¥ng c·ª• thu th·∫≠p th√¥ng tin n√¢ng cao v√† ETL ƒë∆∞·ª£c vi·∫øt b·∫±ng C#/WPF.
* [SkyScraper](https://github.com/JonCanning/SkyScraper) - Tr√¨nh qu√©t web / tr√¨nh thu th·∫≠p d·ªØ li·ªáu web kh√¥ng ƒë·ªìng b·ªô s·ª≠ d·ª•ng kh√¥ng ƒë·ªìng b·ªô / ch·ªù ƒë·ª£i Reactive Extensions.
* [Infinity Crawler](https://github.com/TurnerSoftware/InfinityCrawler) - Th∆∞ vi·ªán tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒë∆°n gi·∫£n nh∆∞ng m·∫°nh m·∫Ω trong C#.

## JavaScript
* [scraperjs](https://github.com/ruipgil/scraperjs) - M·ªôt c√¥ng c·ª• qu√©t web ho√†n ch·ªânh v√† linh ho·∫°t.
* [scrape-it](https://github.com/IonicaBizau/scrape-it) - M·ªôt c√¥ng c·ª• c·∫°p Node.js d√†nh cho con ng∆∞·ªùi.
* [simplecrawler](https://github.com/cgiffard/node-simplecrawler) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web h∆∞·ªõng s·ª± ki·ªán.
* [node-crawler](https://github.com/bda-research/node-crawler) - Tr√¨nh thu th·∫≠p th√¥ng tin n√∫t c√≥ api ƒë∆°n gi·∫£n, r√µ r√†ng.
* [js-crawler](https://github.com/antivanov/js-crawler) - Tr√¨nh thu th·∫≠p th√¥ng tin web cho Node.JS, c·∫£ HTTP v√† HTTPS ƒë·ªÅu ƒë∆∞·ª£c h·ªó tr·ª£.
* [webster](https://github.com/zhuyingda/webster) - M·ªôt khung thu th·∫≠p d·ªØ li·ªáu web ƒë√°ng tin c·∫≠y c√≥ th·ªÉ qu√©t n·ªôi dung ƒë∆∞·ª£c hi·ªÉn th·ªã b·∫±ng ajax v√† js trong m·ªôt trang web.
* [x-ray](https://github.com/lapwinglabs/x-ray) - Tr√¨nh qu√©t web c√≥ h·ªó tr·ª£ ph√¢n trang v√† tr√¨nh thu th·∫≠p th√¥ng tin.
* [node-osmosis](https://github.com/rchipka/node-osmosis) - Tr√¨nh ph√¢n t√≠ch c√∫ ph√°p HTML/XML v√† tr√¨nh qu√©t web cho Node.js.
* [web-scraper-chrome-extension](https://github.com/martinsbalodis/web-scraper-chrome-extension) - C√¥ng c·ª• tr√≠ch xu·∫•t d·ªØ li·ªáu web ƒë∆∞·ª£c tri·ªÉn khai d∆∞·ªõi d·∫°ng ti·ªán √≠ch m·ªü r·ªông c·ªßa chrome.
* [supercrawler](https://github.com/brendonboshell/supercrawler) - X√°c ƒë·ªãnh tr√¨nh x·ª≠ l√Ω t√πy ch·ªânh ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung. Tu√¢n theo robots.txt, gi·ªõi h·∫°n t·ªëc ƒë·ªô v√† gi·ªõi h·∫°n t∆∞∆°ng tranh.
* [headless-chrome-crawler](https://github.com/yujiosaka/headless-chrome-crawler) - Thu th·∫≠p d·ªØ li·ªáu Headless Chrome v·ªõi s·ª± h·ªó tr·ª£ c·ªßa jQuery
* [Squidwarc](https://github.com/n0tan3rd/squidwarc) - Tr√¨nh thu th·∫≠p th√¥ng tin l∆∞u tr·ªØ, c√≥ ƒë·ªô ch√≠nh x√°c cao, c√≥ th·ªÉ s·ª≠ d·ª•ng t·∫≠p l·ªánh, s·ª≠ d·ª•ng Chrome ho·∫∑c Chrome c√≥ ho·∫∑c kh√¥ng c√≥ ph·∫ßn head
* [crawlee](https://github.com/apify/crawlee) - Th∆∞ vi·ªán t·ª± ƒë·ªông h√≥a tr√¨nh duy·ªát v√† qu√©t web d√†nh cho Node.js gi√∫p b·∫°n x√¢y d·ª±ng c√°c tr√¨nh thu th·∫≠p th√¥ng tin ƒë√°ng tin c·∫≠y. Nhanh. 


## PHP
* [Goutte](https://github.com/FriendsOfPHP/Goutte) - Th∆∞ vi·ªán qu√©t m√†n h√¨nh v√† thu th·∫≠p d·ªØ li·ªáu web cho PHP.
    * [laravel-goutte](https://github.com/dweidner/laravel-goutte) - Laravel 5 Facade cho Goutte.
* [dom-crawler](https://github.com/symfony/dom-crawler) - Th√†nh ph·∫ßn DomCrawler gi√∫p d·ªÖ d√†ng ƒëi·ªÅu h∆∞·ªõng DOM cho c√°c t√†i li·ªáu HTML v√† XML.
* [QueryList](https://github.com/jae-jae/QueryList) - Framework thu th·∫≠p th√¥ng tin PHP l≈©y ti·∫øn.
* [pspider](https://github.com/hightman/pspider) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web song song ƒë∆∞·ª£c vi·∫øt b·∫±ng PHP.
* [php-spider](https://github.com/mvdbos/php-spider) - M·ªôt spider web PHP c√≥ th·ªÉ ƒë·ªãnh c·∫•u h√¨nh v√† m·ªü r·ªông.
* [spatie/crawler](https://github.com/spatie/crawler) - M·ªôt tr√¨nh thu th·∫≠p th√¥ng tin m·∫°nh m·∫Ω, d·ªÖ s·ª≠ d·ª•ng ƒë∆∞·ª£c tri·ªÉn khai trong PHP. C√≥ th·ªÉ th·ª±c thi Javascript.
* [crawlzone/crawlzone](https://github.com/crawlzone/crawlzone) - Crawlzone l√† m·ªôt khung thu th·∫≠p d·ªØ li·ªáu internet kh√¥ng ƒë·ªìng b·ªô nhanh ch√≥ng d√†nh cho PHP.
* [PHPScraper](https://github.com/spekulatius/PHPScraper) - PHPScraper l√† m·ªôt tr√¨nh thu th·∫≠p th√¥ng tin & thu th·∫≠p th√¥ng tin ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ ƒë∆°n gi·∫£n h√≥a.

## C++
* [open-source-search-engine](https://github.com/gigablast/open-source-search-engine) - M·ªôt c√¥ng c·ª• t√¨m ki·∫øm ngu·ªìn m·ªü ph√¢n t√°n v√† tr√¨nh thu th·∫≠p th√¥ng tin/tr√¨nh thu th·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c vi·∫øt b·∫±ng C/C++.

## C
* [httrack](https://github.com/xroche/httrack) - Sao ch√©p trang web v√†o m√°y t√≠nh c·ªßa b·∫°n.

## Ruby
* [Nokogiri](https://github.com/sparklemotion/nokogiri) - Rubygem cung c·∫•p tr√¨nh ph√¢n t√≠ch c√∫ ph√°p HTML, XML, SAX v√† Reader v·ªõi h·ªó tr·ª£ b·ªô ch·ªçn XPath v√† CSS.
* [upton](https://github.com/propublica/upton) - M·ªôt framework bao g·ªìm pin (batteries-included) ƒë·ªÉ qu√©t web d·ªÖ d√†ng. Ch·ªâ c·∫ßn th√™m CSS (Ho·∫∑c l√†m nhi·ªÅu h∆°n).
* [wombat](https://github.com/felipecsl/wombat) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu/qu√©t web Ruby nh·∫π v·ªõi DSL thanh l·ªãch gi√∫p tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c t·ª´ c√°c trang.
* [RubyRetriever](https://github.com/joenorton/rubyretriever) - RubyRetriever l√† Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web, Tr√¨nh thu th·∫≠p d·ªØ li·ªáu & Tr√¨nh thu th·∫≠p t·ªáp.
* [Spidr](https://github.com/postmodern/spidr) - T√¨m ki·∫øm m·ªôt trang web, nhi·ªÅu t√™n mi·ªÅn, li√™n k·∫øt nh·∫•t ƒë·ªãnh ho·∫∑c `v√¥ c√πng`.
* [Cobweb](https://github.com/stewartmckee/cobweb) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web v·ªõi c√°c t√πy ch·ªçn thu th·∫≠p th√¥ng tin r·∫•t linh ho·∫°t, ƒë·ªôc l·∫≠p ho·∫∑c s·ª≠ d·ª•ng sidekiq.
* [mechanize](https://github.com/sparklemotion/mechanize) - T∆∞∆°ng t√°c v√† thu th·∫≠p d·ªØ li·ªáu web t·ª± ƒë·ªông.

## Rust
* [spider](https://github.com/spider-rs/spider) - Tr√¨nh thu th·∫≠p th√¥ng tin v√† l·∫≠p ch·ªâ m·ª•c web nhanh nh·∫•t.
* [crawler](https://github.com/a11ywatch/crawler) - Tr√¨nh l·∫≠p ch·ªâ m·ª•c web gRPC ƒë∆∞·ª£c t√≠nh ph√≠ cho hi·ªáu su·∫•t.

## R
* [rvest](https://github.com/hadley/rvest) - Qu√©t web ƒë∆°n gi·∫£n cho R.

## Erlang 
* [ebot](https://github.com/matteoredaelli/ebot) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web c√≥ kh·∫£ nƒÉng m·ªü r·ªông, ph√¢n t√°n v√† c√≥ c·∫•u h√¨nh cao.

## Perl
* [web-scraper](https://github.com/miyagawa/web-scraper) - B·ªô c√¥ng c·ª• qu√©t web s·ª≠ d·ª•ng B·ªô ch·ªçn HTML v√† CSS ho·∫∑c bi·ªÉu th·ª©c XPath.

## Go
* [pholcus](https://github.com/henrylee2cn/pholcus) -  Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web m·∫°nh m·∫Ω, c√≥ t√≠nh ƒë·ªìng th·ªùi cao v√† ph√¢n t√°n.
* [gocrawl](https://github.com/PuerkitoBio/gocrawl) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web l·ªãch s·ª±, m·ªèng v√† ƒë·ªìng th·ªùi.
* [fetchbot](https://github.com/PuerkitoBio/fetchbot) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒë∆°n gi·∫£n v√† linh ho·∫°t tu√¢n theo c√°c ch√≠nh s√°ch c·ªßa robots.txt v√† ƒë·ªô tr·ªÖ thu th·∫≠p d·ªØ li·ªáu.
* [go_spider](https://github.com/hu17889/go_spider) - M·ªôt framework tuy·ªát v·ªùi d√†nh cho Go concurrent Crawler(spider).
* [dht](https://github.com/shiyanhui/dht) - Giao th·ª©c BitTorrent DHT && DHT Spider.
* [ants-go](https://github.com/wcong/ants-go) - M·ªôt c√¥ng c·ª• thu th·∫≠p th√¥ng tin m√£ ngu·ªìn m·ªü, ph√¢n t√°n, restful ·ªü golang.
* [scrape](https://github.com/yhat/scrape) - M·ªôt giao di·ªán ƒë∆°n gi·∫£n, c·∫•p ƒë·ªô cao h∆°n ƒë·ªÉ qu√©t web tr√™n Go.
* [creeper](https://github.com/wspl/creeper) - Framework thu th·∫≠p th√¥ng tin th·∫ø h·ªá ti·∫øp theo (Go).
* [colly](https://github.com/asciimoo/colly) - Framework qu√©t nhanh v√† thanh l·ªãch d√†nh cho Gophers.
* [ferret](https://github.com/MontFerret/ferret) - Declarative web scraping.
* [Dataflow kit](https://github.com/slotix/dataflowkit) - Tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c t·ª´ c√°c trang web. C√°c trang web c·∫°o. Web sites scraping.
* [Hakrawler](https://github.com/hakluke/hakrawler) - Tr√¨nh thu th·∫≠p d·ªØ li·ªáu web ƒë∆°n gi·∫£n, nhanh ch√≥ng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ kh√°m ph√° d·ªÖ d√†ng, nhanh ch√≥ng c√°c ƒëi·ªÉm cu·ªëi v√† n·ªôi dung trong ·ª©ng d·ª•ng web

## Scala
* [crawler](https://github.com/bplawler/crawler) - Scala DSL ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu web.
* [scrala](https://github.com/gaocegege/scrala) - Khung tr√¨nh thu th·∫≠p d·ªØ li·ªáu Scala (nh·ªán), l·∫•y c·∫£m h·ª©ng t·ª´ Scrapy.
* [ferrit](https://github.com/reggoodwin/ferrit) - Ferrit l√† d·ªãch v·ª• thu th·∫≠p d·ªØ li·ªáu web ƒë∆∞·ª£c vi·∫øt b·∫±ng Scala s·ª≠ d·ª•ng Akka, Spray v√† Cassandra.


## T·ªïng k·∫øt

V·ªÅ c∆° b·∫£n ƒë·ªÉ x√¢y d·ª±ng m·ªôt ·ª©ng d·ª•ng crawler, c√≥ r·∫•t nhi·ªÅu c√°ch v√† tr√™n ƒë√¢y l√† c√°ch m√¨nh ƒë√£ ti·∫øp c·∫≠n. Hy v·ªçng s·∫Ω gi√∫p ƒë∆∞·ª£c b·∫°n x√¢y d·ª±ng ƒë∆∞·ª£c m·ªôt h·ªá th·ªëng crawler nh∆∞ mong mu·ªën.


-----
Tham kh·∫£o:
- [Crawling d·ªØ li·ªáu t·ª´ website, t√¨m hi·ªÉu v·ªÅ ScrapingWeb](https://viblo.asia/p/crawling-du-lieu-tu-website-tim-hieu-ve-scrapingweb-1VgZvGo9lAw)
- [[B√†n ti·∫øp v·ªÅ Crawling] Qu√©t d·ªØ li·ªáu b·∫•t ƒë·ªông s·∫£n b·∫±ng Python](https://viblo.asia/p/ban-tiep-ve-crawling-quet-du-lieu-bat-dong-san-bang-python-RnB5pzo6ZPG)
- [Data Scraping Tools for Scraping Real Estate Data Using Python](https://www.promptcloud.com/blog/scraping-real-estate-data-from-zillow-using-python/)
- [Crawl data - c√†o d·ªØ li·ªáu c√≥ g√¨ kh√≥?](https://www.lhsang.dev/posts/technique/scraping-data-from-websites/)
- [T√¨m hi·ªÉu chung v·ªÅ Web Scraping v√† c√°c v·∫•n ƒë·ªÅ c·∫ßn quan t√¢m](https://viblo.asia/p/tim-hieu-chung-ve-web-scraping-va-cac-van-de-can-quan-tam-djeZ1yXJZWz)
- [T√¨m hi·ªÉu v·ªÅ Web Scraping Bot l√† g√¨?](https://securitydaily.net/tim-hieu-ve-web-scraping-bot-la-gi/)
- [X√¢y d·ª±ng s∆° b·ªô m·ªôt h·ªá th·ªëng crawler](https://viblo.asia/p/xay-dung-so-bo-mot-he-thong-crawler-aWj538BQK6m)
- [Panther - th∆∞ vi·ªán d√πng ƒë·ªÉ scrape website](https://viblo.asia/p/panther-thu-vien-dung-de-scrape-website-ORNZqp3bK0n)
- [C√°ch m√¨nh "hack" ƒë∆∞·ª£c v√†o h·∫π th·ªëng c·ªßa SMAS ƒë·ªÉ xem ƒëi·ªÉm.](https://viblo.asia/p/cach-minh-hack-duoc-vao-he-thong-cua-smas-de-xem-diem-LzD5d2rYZjY)
- [M·ªôt v√†i c√¥ng c·ª• d√≤ qu√©t l·ªó h·ªïng XSS hi·ªáu qu·∫£ khi sƒÉn bug](https://viblo.asia/p/mot-vai-cong-cu-do-quet-lo-hong-xss-hieu-qua-khi-san-bug-x7Z4Djm0LnX)
- [C√°ch crawl data "no code" ƒë∆°n gi·∫£n v·ªõi Chrome Extension](https://viblo.asia/p/cach-crawl-data-no-code-don-gian-voi-chrome-extension-obA4660w4Kv)

-----
Python - [Scrapy](https://scrapy.org), [pyspider](http://docs.pyspider.org), [CoCrawler](https://github.com/cocrawler/cocrawler), [cola](https://github.com/qinxuye/cola), [Demiurge](http://demiurge.readthedocs.org/), [Scrapely](https://github.com/scrapy/scrapely) .v.v.

- [C√†o d·ªØ li·ªáu v·ªõi Scrapy](https://phocode.com/python/scrapy/scrapy-gioi-thieu/)
- [L√†m m·ªôt con Crawler ƒë∆°n gi·∫£n ƒë·ªÉ c√†o ebooks v·ªõi Scrapy v√† python](https://viblo.asia/p/lam-mot-con-crawler-don-gian-de-cao-ebooks-voi-scrapy-va-python-maGK7qPDlj2)
- [Thu th·∫≠p v√† l∆∞u tr·ªØ d·ªØ li·ªáu v·ªõi scrapy v√† mysql](https://viblo.asia/p/thu-thap-va-luu-tru-du-lieu-voi-scrapy-va-mysql-yMnKMA9EK7P)
- [Thu th·∫≠p d·ªØ li·ªáu t·ª± ƒë·ªông c√πng v·ªõi Scrapy, Mongodb v√† Crontab](https://viblo.asia/p/thu-thap-du-lieu-tu-dong-cung-voi-scrapy-mongodb-va-crontab-RQqKLNrml7z)
- [T·∫≠p t√†nh crawl d·ªØ li·ªáu v·ªõi Scrapy Framework](https://viblo.asia/p/tap-tanh-crawl-du-lieu-voi-scrapy-framework-bWrZnW7rlxw)
- [Crawl d·ªØ li·ªáu trang web v·ªõi Scrapy](https://viblo.asia/p/crawl-du-lieu-trang-web-voi-scrapy-E375zWr1KGW)
- [S·ª± k·∫øt h·ª£p ho√†n h·∫£o c·ªßa Scrapy v√† Splash - Gi·∫£i ph√°p t·ªëi ∆∞u v·ªõi trang web s·ª≠ d·ª•ng Javascript?](https://viblo.asia/p/su-ket-hop-hoan-hao-cua-scrapy-va-splash-giai-phap-toi-uu-voi-trang-web-su-dung-javascript-Qbq5Qa8w5D8)
- [S·ª± k·∫øt h·ª£p ho√†n h·∫£o c·ªßa Scrapy v√† Splash (Ph·∫ßn 2)](https://viblo.asia/p/su-ket-hop-hoan-hao-cua-scrapy-va-splash-phan-2-1VgZvVApZAw)
- [Thu th·∫≠p d·ªØ li·ªáu v·ªõi Scrapy, Splash - N·ªôi dung ƒë∆∞·ª£c t·∫°o b·ªüi JavaScript](https://viblo.asia/p/thu-thap-du-lieu-voi-scrapy-splash-noi-dung-duoc-tao-boi-javascript-3Q75wBbMlWb)
- [V√≠ d·ª• v·ªÅ vi·ªác thu th·∫≠p d·ªØ li·ªáu Web v·ªõi Scrapy](https://viblo.asia/p/vi-du-ve-viec-thu-thap-du-lieu-web-voi-scrapy-aWj53kBY56m)
- [Gi·ªõi thi·ªáu/h∆∞·ªõng d·∫´n v·ªÅ Crawler v·ªõi Scrapy Framework](https://viblo.asia/p/gioi-thieuhuong-dan-ve-crawler-voi-scrapy-framework-ByEZkWoEZQ0)
- [Gi·ªõi thi·ªáu/h∆∞·ªõng d·∫´n v·ªÅ Crawler v·ªõi Scrapy Framework (Ph·∫ßn 2)](https://viblo.asia/p/gioi-thieuhuong-dan-ve-crawler-voi-scrapy-framework-phan-2-YWOZry7pKQ0)
- [Gi·ªõi thi·ªáu/h∆∞·ªõng d·∫´n v·ªÅ Crawler v·ªõi Scrapy Framework (Ph·∫ßn 3)](https://viblo.asia/p/gioi-thieuhuong-dan-ve-crawler-voi-scrapy-framework-phan-3-gDVK2kovZLj)
- [Scraping v√† crawling Web v·ªõi Scrapy v√† SQLAlchemy](https://viblo.asia/p/scraping-va-crawling-web-voi-scrapy-va-sqlalchemy-6BkGyxOLM5aV)
- [K·ªπ thu·∫≠t scraping v√† crawling Web n√¢ng cao v·ªõi Scrapy v√† SQLAlchemy](https://viblo.asia/p/ky-thuat-scraping-va-crawling-web-nang-cao-voi-scrapy-va-sqlalchemy-6BkGyxzeM5aV)
- [S·ª≠ d·ª•ng proxy trong Scrapy](https://viblo.asia/p/su-dung-proxy-trong-scrapy-maGK780LZj2)
- [T√¨m hi·ªÉu c√°ch c√†o d·ªØ li·ªáu ƒë∆°n gi·∫£n v·ªõi Scapy](https://viblo.asia/p/tim-hieu-cach-cao-du-lieu-don-gian-voi-scapy-3P0lPDA4lox)

#### Scrapy for Beginners
- _John Watson Rooney &#9679; [15 video](https://www.youtube.com/playlist?list=PLRzwgpycm-Fjvdf7RpmxnPMyJ80RecJjv) &#9679; Dec 10, 2020_

#### Scrapy
- _codeRECODE &#9679; [40 video](https://www.youtube.com/playlist?list=PLj4hN6FewnwoUArmA8kifDHZYvRn6egg5) &#9679; Jun 7, 2023_

#### The Python Scrapy Playbook
- _ScrapeOps &#9679; [20 video](https://www.youtube.com/playlist?list=PLkhQp3-EGsIi39YF-BE306DDX1xVSTHmn) &#9679; Dec 12, 2020_

#### Python Web Scraping & Crawling using Scrapy
- _buildwithpython &#9679; [25 video](https://www.youtube.com/playlist?list=PLhTjy8cBISEqkN-5Ku_kXG4QW33sxQo0t) &#9679; Feb 25, 2019_

- [Scrapy Course ‚Äì Python Web Scraping for Beginners](https://youtu.be/mBoX_JCKZTE)
- [Scraping LinkedIn Profiles with Python Scrapy (2022)](https://youtu.be/fg8ZGzueHLk)


Python - Beautiful Soup
- [PyMOTM: Argparse](https://viblo.asia/p/pymotm-argparse-l5XRBVeVRqPe)
- [PyMOTM: Requests](https://viblo.asia/p/pymotm-requests-zb7vD8wKvjKd)
- [PyMOTM: Beautiful Soup 4 (Part I)](https://viblo.asia/p/pymotm-beautiful-soup-4-part-i-DljMbVZZMVZn)
- [PyMOTM: Beautiful Soup 4 (Part II)](https://viblo.asia/p/pymotm-beautiful-soup-4-part-ii-amoG81yOvz8P)
- [PyMOTM: Beautiful Soup 4 (Part III)](https://viblo.asia/p/pymotm-beautiful-soup-4-part-iii-XqaGEBJEeWK)
- [C√°ch scrape m·ªôt trang web b·∫±ng python v√† BeautifulSoup](https://viblo.asia/p/cach-scrape-mot-trang-web-bang-python-va-beautifulsoup-vyDZODwPlwj)

-----
JavaScript
- ["ƒê√†o m·ªè" v·ªõi Puppeteer](https://viblo.asia/p/dao-mo-voi-puppeteer-924lJEg6ZPM)
- [Web Scraping v·ªõi Nuxtjs s·ª≠ d·ª•ng Puppeteer](https://viblo.asia/p/web-scraping-voi-nuxtjs-su-dung-puppeteer-gDVK2L8vlLj)
- [Crawl website s·ª≠ d·ª•ng Node.js v√† Puppeteer - ph·∫ßn 1](https://viblo.asia/p/crawl-website-su-dung-nodejs-va-puppeteer-phan-1-L4x5xv2wZBM)
- [Crawl website s·ª≠ d·ª•ng Node.js v√† Puppeteer - ph·∫ßn 2](https://viblo.asia/p/crawl-website-su-dung-nodejs-va-puppeteer-phan-2-3P0lP1kn5ox)
- [Crawl data using laravel , proxy and simple html dom](https://viblo.asia/p/crawl-data-using-laravel-proxy-and-simple-html-dom-Az45bojwKxY)
- [[P1] T√¨m hi·ªÉu Headless browser & Puppeteer](https://viblo.asia/p/p1-tim-hieu-headless-browser-puppeteer-63vKjngdK2R)
- [[P2] - L·∫•y d·ªØ li·ªáu website b·∫±ng puppeteer](https://viblo.asia/p/p2-lay-du-lieu-website-bang-puppeteer-YWOZryPvKQ0)
- [Build extension to check timesheet on WSM (P1)](https://viblo.asia/p/build-extension-to-check-timesheet-on-wsm-p1-aWj538N1K6m)
- [X√¢y d·ª±ng extension ƒë·ªÉ check timesheet tr√™n WSM (P2)](https://viblo.asia/p/xay-dung-extension-de-check-timesheet-tren-wsm-p2-OeVKB4JMlkW)

-----
PHP
- [Crawl d·ªØ li·ªáu Website s·ª≠ d·ª•ng k·ªπ thu·∫≠t ph√¢n t√≠ch c√∫ ph√°p XML b·∫±ng PHP](https://itnavi.com.vn/blog/crawl-du-lieu-website-su-dung-ky-thuat-phan-tich-cu-phap-xml-bang-php)
- [Crawl Data b·∫±ng Laravel v√† Goutte](https://viblo.asia/p/crawl-data-bang-laravel-va-goutte-L4x5x3ewlBM)

-----
Ruby - Nokogiri, upton, wombat, RubyRetriever, Spidr, Cobweb, mechanize
- [Crawl Data v√† Scrape Data](https://viblo.asia/p/ruby-crawl-data-va-scrape-data-yZjJY9RbJOE)
- [Crawl d·ªØ li·ªáu trong Rails v·ªõi gem Mechanize](https://viblo.asia/p/crawl-du-lieu-trong-rails-voi-gem-mechanize-LzD5dLv05jY)
- [Th·ª≠ crawling d·ªØ li·ªáu Viblo b·∫±ng Mechanize gem](https://viblo.asia/p/thu-crawling-du-lieu-viblo-bang-mechanize-gem-RQqKLLLrK7z)
- [X√¢y d·ª±ng web crawler c∆° b·∫£n v·ªõi mechanize](https://viblo.asia/p/xay-dung-web-crawler-co-ban-voi-mechanize-RnB5pnJYZPG)
- [Scrape websites with Ruby & Mechanize](https://viblo.asia/p/scrape-websites-with-ruby-mechanize-DzVkpmoKvnW)
- [Web crawler v√† scrape data v·ªõi gem Mechanize](https://viblo.asia/p/web-crawler-va-scrape-data-voi-gem-mechanize-eBYjv410RxpV)
- [Web crawler n√¢ng cao v·ªõi Mechanize (P1)](https://viblo.asia/p/web-crawler-nang-cao-voi-mechanize-p1-YrEBRAQLR8Zj)
- [Web crawler n√¢ng cao v·ªõi Mechanize (P2)](https://viblo.asia/p/web-crawler-nang-cao-voi-mechanize-p2-ojaqG0nVREKw)

-----
Go - pholcus, gocrawl, fetchbot, go_spider, dht, ants-go, scrape, creeper, colly, ferret, Dataflow kit, Hakrawler
- [Thu th·∫≠p d·ªØ li·ªáu v·ªõi Golang Colly](https://viblo.asia/p/thu-thap-du-lieu-voi-golang-colly-924lJ3y85PM)
- [S·ª≠ d·ª•ng chromedp v·ªõi golang ƒë·ªÉ crawl c√°c trang web c√≥ n·ªôi dung ƒë∆∞·ª£c t·∫°o b·ªüi javascript](https://viblo.asia/p/su-dung-chromedp-voi-golang-de-crawl-cac-trang-web-co-noi-dung-duoc-tao-boi-javascript-4P856GWLKY3)

-----
- [Awesome-Crawler](https://github.com/BruceDone/awesome-crawler)
- [https://viblo.asia/tags/crawl](https://viblo.asia/tags/crawl)
- [https://viblo.asia/tags/crawling](https://viblo.asia/tags/crawling)
- [https://viblo.asia/tags/web-crawler](https://viblo.asia/tags/web-crawler)
- [https://viblo.asia/tags/scraping](https://viblo.asia/tags/scraping)
- [https://viblo.asia/tags/scrapy](https://viblo.asia/tags/scrapy)
- [https://viblo.asia/tags/selenium](https://viblo.asia/tags/selenium)
- [https://viblo.asia/search?q=Cheerio](https://viblo.asia/search?q=Cheerio)
- [https://viblo.asia/tags/puppeteer](https://viblo.asia/tags/puppeteer)
- [https://viblo.asia/tags/mechanize](https://viblo.asia/tags/mechanize)

-----
- [Web Data Crawling vs Web Data Scraping](https://www.promptcloud.com/blog/data-scraping-vs-data-crawling/)
- [Web scraping in 2023 ‚Äî Breaking it down to basics](https://blog.devgenius.io/webscraping-in-2023-breaking-it-down-to-basics-programming-learning-scraping-python-web-data-science-10fa130cc8be)

-----
eBook:

- [Getting Started with Python Web Scraping](https://www.oreilly.com/library/view/getting-started-with/9781787283244/), [Code samples](https://github.com/PacktPublishing/Getting-Started-with-Python-Web-Scraping-V-)
- [Web Scraping Tutorial with Scrapy and Python for Beginners](https://www.oreilly.com/library/view/web-scraping-tutorial/9781804615317/), [Code samples](https://github.com/PacktPublishing/Web-Scraping-Tutorial-with-Scrapy-and-Python-for-Beginners-)
- [Web Scraping with Python](https://www.linkedin.com/learning/web-scraping-with-python), [Code samples](https://github.com/LinkedInLearning/web-scraping-with-python-2848331)
- [Web Scraping with Python, 2nd Edition](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/), [Code samples](https://github.com/REMitchell/python-scraping)
- [Hands-On Web Scraping with Python](https://packt.link/free-ebook/9781789533392), [Code samples](https://github.com/PacktPublishing/Hands-On-Web-Scraping-with-Python)
- [Python Web Scraping Cookbook](https://www.oreilly.com/library/view/python-web-scraping/9781787285217/), [Code samples](https://github.com/PacktPublishing/Python-Web-Scraping-Cookbook/)
- [Go Web Scraping Quick Start Guide](https://www.oreilly.com/library/view/go-web-scraping/9781789615708/), [Code samples](https://github.com/PacktPublishing/Go-Web-Scraping-Quick-Start-Guide)
- [Website Scraping with Python: Using BeautifulSoup and Scrapy](https://www.oreilly.com/library/view/website-scraping-with/9781484239254/), [Code samples](https://github.com/sanikamal/web-scraping-with-python)
- [Instant PHP Web Scraping](https://www.amazon.com/Instant-PHP-Scraping-Jacob-Ward/dp/1782164766), [Code samples](https://github.com/freelancerwebro/web-scraping-instant)
- [50 Hours of Big Data, PySpark, AWS, Scala, and Scraping](https://www.oreilly.com/library/view/50-hours-of/9781803237039/), [Code samples](https://github.com/PacktPublishing/50-Hours-of-Big-Data-PySpark-AWS-Scala-and-Scraping)
- [R Web Scraping Quick Start Guide](https://www.oreilly.com/library/view/r-web-scraping/9781789138733/), [Code samples](https://github.com/PacktPublishing/R-Web-Scraping-Quick-Start-Guide)
- [Learning Scrapy - Second Edition](https://www.packtpub.com/product/learning-scrapy-second-edition/9781788627450), [Code samples](https://github.com/scalingexcellence/scrapybook-2nd-edition)

-----

<img align="right" src="https://learning.oreilly.com/library/cover/9781804615317/250w/" alt="Web Scraping Tutorial with Scrapy and Python for Beginners" title="Web Scraping Tutorial with Scrapy and Python for Beginners">

<img align="right" src="https://learning.oreilly.com/library/cover/9781098145347/250w/" alt="Web Scraping with Python, 3rd Edition" title="Web Scraping with Python, 3rd Edition">

<img align="right" src="https://learning.oreilly.com/library/cover/9781491985564/250w/" alt="Web Scraping with Python, 2nd Edition" title="Web Scraping with Python, 2nd Edition">

<img align="right" src="https://learning.oreilly.com/library/cover/9781782164364/250w/" alt="Web Scraping with Python" title="Web Scraping with Python">

<img align="right" src="https://learning.oreilly.com/library/cover/9781789533392/250w" alt="Hands-On Web Scraping with Python" title="Hands-On Web Scraping with Python">

<img align="right" src="https://learning.oreilly.com/library/cover/9781787285217/250w/" alt="Python Web Scraping Cookbook" title="Python Web Scraping Cookbook">

![Go Web Scraping Quick Start Guide](https://learning.oreilly.com/library/cover/9781789615708/250w/ "Go Web Scraping Quick Start Guide")

-----